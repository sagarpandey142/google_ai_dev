<!-- Do not edit this file. It is automatically generated by API Documenter. -->

[Home](./index.md) &gt; [@google/generative-ai](./generative-ai.md)

## generative-ai package

## Classes

|  Class | Description |
|  --- | --- |
|  [ChatSession](./generative-ai.chatsession.md) | ChatSession class that enables sending chat messages and stores history of sent and received messages so far. |
|  [GenerativeModel](./generative-ai.generativemodel.md) | Class for generative model APIs. |
|  [GoogleGenerativeAI](./generative-ai.googlegenerativeai.md) | Top-level class for this SDK |

## Enumerations

|  Enumeration | Description |
|  --- | --- |
|  [BlockReason](./generative-ai.blockreason.md) | Reason that a prompt was blocked. |
|  [FinishReason](./generative-ai.finishreason.md) | Reason that a candidate finished. |
|  [HarmBlockThreshold](./generative-ai.harmblockthreshold.md) | Threshhold above which a prompt or candidate will be blocked. |
|  [HarmCategory](./generative-ai.harmcategory.md) | Harm categories that would cause prompts or candidates to be blocked. |
|  [HarmProbability](./generative-ai.harmprobability.md) | Probability that a prompt or candidate matches a harm category. |
|  [TaskType](./generative-ai.tasktype.md) | Task type for embedding content. |

## Interfaces

|  Interface | Description |
|  --- | --- |
|  [BaseParams](./generative-ai.baseparams.md) | Base parameters for a number of methods. |
|  [BatchEmbedContentsRequest](./generative-ai.batchembedcontentsrequest.md) | Params for calling [GenerativeModel.batchEmbedContents()](./generative-ai.generativemodel.batchembedcontents.md) |
|  [BatchEmbedContentsResponse](./generative-ai.batchembedcontentsresponse.md) | Response from calling [GenerativeModel.batchEmbedContents()](./generative-ai.generativemodel.batchembedcontents.md)<!-- -->. |
|  [CitationMetadata](./generative-ai.citationmetadata.md) | Citation metadata that may be found on a [GenerateContentCandidate](./generative-ai.generatecontentcandidate.md)<!-- -->. |
|  [CitationSource](./generative-ai.citationsource.md) | A single citation source. |
|  [Content](./generative-ai.content.md) | Content type for both prompts and response candidates. |
|  [ContentEmbedding](./generative-ai.contentembedding.md) | A single content embedding. |
|  [CountTokensRequest](./generative-ai.counttokensrequest.md) | Params for calling [GenerativeModel.countTokens()](./generative-ai.generativemodel.counttokens.md) |
|  [CountTokensResponse](./generative-ai.counttokensresponse.md) | Response from calling [GenerativeModel.countTokens()](./generative-ai.generativemodel.counttokens.md)<!-- -->. |
|  [EmbedContentRequest](./generative-ai.embedcontentrequest.md) | Params for calling [GenerativeModel.embedContent()](./generative-ai.generativemodel.embedcontent.md) |
|  [EmbedContentResponse](./generative-ai.embedcontentresponse.md) | Response from calling [GenerativeModel.embedContent()](./generative-ai.generativemodel.embedcontent.md)<!-- -->. |
|  [EnhancedGenerateContentResponse](./generative-ai.enhancedgeneratecontentresponse.md) | Response object wrapped with helper methods. |
|  [GenerateContentCandidate](./generative-ai.generatecontentcandidate.md) | A candidate returned as part of a [GenerateContentResponse](./generative-ai.generatecontentresponse.md)<!-- -->. |
|  [GenerateContentRequest](./generative-ai.generatecontentrequest.md) | Request sent to <code>generateContent</code> endpoint. |
|  [GenerateContentResponse](./generative-ai.generatecontentresponse.md) | Individual response from [GenerativeModel.generateContent()](./generative-ai.generativemodel.generatecontent.md) and [GenerativeModel.generateContentStream()](./generative-ai.generativemodel.generatecontentstream.md)<!-- -->. <code>generateContentStream()</code> will return one in each chunk until the stream is done. |
|  [GenerateContentResult](./generative-ai.generatecontentresult.md) | Result object returned from generateContent() call. |
|  [GenerateContentStreamResult](./generative-ai.generatecontentstreamresult.md) | Result object returned from generateContentStream() call. Iterate over <code>stream</code> to get chunks as they come in and/or use the <code>response</code> promise to get the aggregated response when the stream is done. |
|  [GenerationConfig](./generative-ai.generationconfig.md) | Config options for content-related requests |
|  [GenerativeContentBlob](./generative-ai.generativecontentblob.md) | Interface for sending an image. |
|  [InlineDataPart](./generative-ai.inlinedatapart.md) | Content part interface if the part represents an image. |
|  [InputContent](./generative-ai.inputcontent.md) | Content that can be provided as history input to startChat(). |
|  [ModelParams](./generative-ai.modelparams.md) | Params passed to [GoogleGenerativeAI.getGenerativeModel()](./generative-ai.googlegenerativeai.getgenerativemodel.md)<!-- -->. |
|  [PromptFeedback](./generative-ai.promptfeedback.md) | If the prompt was blocked, this will be populated with <code>blockReason</code> and the relevant <code>safetyRatings</code>. |
|  [RequestOptions](./generative-ai.requestoptions.md) | Params passed to [GoogleGenerativeAI.getGenerativeModel()](./generative-ai.googlegenerativeai.getgenerativemodel.md)<!-- -->. |
|  [SafetyRating](./generative-ai.safetyrating.md) | A safety rating associated with a [GenerateContentCandidate](./generative-ai.generatecontentcandidate.md) |
|  [SafetySetting](./generative-ai.safetysetting.md) | Safety setting that can be sent as part of request parameters. |
|  [StartChatParams](./generative-ai.startchatparams.md) | Params for [GenerativeModel.startChat()](./generative-ai.generativemodel.startchat.md)<!-- -->. |
|  [TextPart](./generative-ai.textpart.md) | Content part interface if the part represents a text string. |

## Type Aliases

|  Type Alias | Description |
|  --- | --- |
|  [Part](./generative-ai.part.md) | Content part - includes text or image part types. |

